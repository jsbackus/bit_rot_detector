#!/usr/bin/python

import logging
import os
from os.path import join
import stat
import hashlib
import argparse
import sqlite3

###########
# Globals #
###########
table_names = { 'files': 'fp_files', 'dirs': 'fp_dirs' }

#############
# Functions #
#############
def parse_args():
    """Sets up the argparse object and attempts to parse the command-line.
    """
    
    # Create parser object
    parser = argparse.ArgumentParser(description=
                                     'Tool verify file integrity.')
    parser.add_argument('-l', '--log', nargs='?', 
                        default='', help='log to file instead of console')
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='only display warnings and errors')
    parser.add_argument('-d', '--debug', action='store_true',
                        help='display debugging information')
    parser.add_argument('--db', default='check_files.db',
                        help='Database that contains file fingerprint info.')
    parser.add_argument('--dry-run', action='store_true',
                        help='prints commands to execute, but don\'t do ' +
                        'anything.')
    parser.add_argument('root_dir', nargs='+', 
                        help='Root of a directory tree to scan and check.')

    # Create namespace from command-line
    return parser.parse_args()

def setup_logger(quiet_mode, debug_mode, filename=''):
    """Sets up the global logging object.
    """

    # Determine log level
    if debug_mode:
        logLevel = logging.DEBUG
    elif quiet_mode:
        logLevel = logging.WARNING
    else:
        logLevel = logging.INFO

    # Start logger with default level
    logging.basicConfig(format='[%(asctime)s %(levelname)s] %(message)s', 
                        datefmt='%Y-%m-%d %I:%M:%S', level=logging.INFO,
                        filename=filename)

    # Denote start of logging, if using a file
    if 0 < len(filename):
        logging.info('Logging started')

    # If logging debug messages, indicate so in file.
    if debug_mode:
        logging.info('Logging debug messages is enabled')

    # Set log level
    logging.getLogger().setLevel(logLevel)

def read_in_chunks(file_obj, chunk_size=1024*1024):
    """Generator to read data from the specified file in chunks.
    Default chunk size is 1M.
    """
    while True:
        data = file_obj.read(chunk_size)
        if not data:
            break
        yield data

def calc_fingerprint(filename):
    """Returns a string containing the SHA1 fingerprint of this file.
    """
    # Create a new SHA1 object and read from the specified file in chunks.
    result = hashlib.sha1()
    with open(filename, 'rb') as f:
        for read_data in read_in_chunks(f):
            result.update(read_data)

    # Return fingerprint
    return result.hexdigest()
    
def get_file_info(location, filename):
    """Returns a tuple containing the file name, directory it lives in, 
    file size, last access time, last modification time, and the finger print.
    """
    # Concatenate path and filename
    path = os.path.join(location, filename)
    # Log the file
    logging.info('Getting info for file \'%s\'', path)
    
    # Grab filesystem info
    mode = os.stat(path)

    # Generate fingerprint
    fp = calc_fingerprint(path)

    # Generate and return tuple
    result = (location, filename, mode.st_size, mode.st_atime, mode.st_mtime, 
              fp)
    return result

def process_root(path, db_conn):
    """Crawls the specified directory, processing all files that it finds.
    """
    
    cursor = db_conn.cursor()

    parent_id = -1

##### There's a bug here: Looks like walk is working depth first, which is
##### screwing up the 'parent id'!

    # Walk the filesystem
    for root, dirs, files in os.walk(path):
        # Log the directory that we are processing
        logging.info('Processing directory \'%s\'', root)

        dirname = os.path.basename(root.rstrip(os.sep))

        # Search the database for this path by name and parent_id.
        # If it doesn't exist, add it. Hold onto this path's id for later.
        cursor.execute("SELECT Path_ID from '" + table_names['dirs'] + 
                       "' WHERE Parent_ID=? AND Name=?",
                       (parent_id, dirname))
        row = cursor.fetchone()
        if row == None:
            cursor.execute("INSERT INTO '" + table_names['dirs'] + 
                           "'(Name, Parent_ID) VALUES(?, ?)", 
                           (dirname, str(parent_id)))
            parent_id = cursor.lastrowid
            logging.debug('Path \'' + root + '\' not in database. Added with ' +
                          'ID = ' + str(parent_id))
        else:
            parent_id = row[0]
            logging.debug('Path \'' + root + '\' found in database with ID = ' +
                          str(parent_id))
    
        ## Process files

        # Fetch the list of all files that have this directory as a parent.
        logging.debug('parent_id = ' + str(parent_id))
        cursor.execute("SELECT Name from '" + table_names['files'] + 
                       "' WHERE Parent_ID=?", (parent_id,))
        files_not_seen = cursor.fetchall()
        
        for name in files:
            info = get_file_info(root, name)
            logging.debug('File info object: %s', info)
            full_name = join(root, name)
            try:
                files_not_seen.remove( (name) )
                logging.debug('Marking file \'' + full_name + '\' as seen.')
                
                # Grab entire record from the database
                cursor.execute("SELECT * from '" + table_names['files'] + 
                               "' WHERE Parent_ID=? and " +
                               "Name=?", (parent_id, name))
                file_rec = cursor.fetchone()

                # Check current file against one in database
                if file_rec == None:
                    logging.error('Error fetching record for file \'' + 
                                  full_name + '\'!')
                elif file_rec[3] != info[6]:
                    # Fingerprints don't match...
                    logging.debug('File \'' + full_name + '\' does not match ' +
                                 'fingerprint in database')
                    
                    # Compare modification times. If this file is newer, update
                    # database. Otherwise issue a warning.
                    if file_rec[3] < info[4]:
                        logging.info('File \'' + full_name + '\' is newer than '
                                     + 'database record. Updating...')
                        cursor.execute("UPDATE '" + table_names['files'] + 
                                       "' SET LastModified=?, " +
                                       "Fingerprint=?, Size=? WHERE File_ID=?",
                                       (info[4], info[5],
                                       info[2], file_rec[0]))
                    else:
                        logging.warning('File \'' + full_name + '\' does not ' +
                                        'match fingerprint in database and is '
                                        'not newer. File could be damaged!')
                else:
                    logging.debug('File \'' + full_name + '\' matches ' +
                                  'fingerprint in database')
                    # Double-check size to make sure we aren't fooling 
                    # ourselves.
                    if file_rec[5] != info[2]:
                        logging.warning('File sizes do not match for file \'' +
                                        full_name + 
                                        '\'! File could be damaged!')
                    else:
                        logging.debug('File \'' + full_name + '\' matches ' +
                                      'file size in database')
                    
            except ValueError:
                # Item not in list - add to database
                cursor.execute("INSERT INTO '" + table_names['files'] + 
                               "'(Name, Parent_ID, LastModified, Fingerprint," +
                               " Size) VALUES(?, ?, ?, ?, ?)", 
                               (name, parent_id,
                               info[4], info[5], info[2]))

                logging.debug('File \'' + join(root,name) + '\' not in ' +
                              'database. Added with ID = ' + 
                              str(cursor.lastrowid))

        ## TO DO
        logging.warning('Files that no longer exist: %s', files_not_seen)
        
        ## Process directories

        # Fetch the list of all directories that have this directory as a 
        # parent.
        cursor.execute("SELECT Name from '" + table_names['dirs'] + 
                       "' WHERE Parent_ID=?", (parent_id,))
        dirs_not_seen = cursor.fetchall()
        
        # Iterate through the list of directories that currently exist on the
        # filesystem. For each directory, if it is in the list of dirs not seen,
        # remove it. If it is not, add it will be added next pass.
        for name in dirs:
            try:
                dirs_not_seen.remove( (name) )
                logging.debug('Marking directory \'' + name + '\' as seen.')
            except ValueError:
                # Item not in list - add to database
                pass
        # TO DO
        logging.warning('Directories that no longer exist: %s', dirs_not_seen)

def open_db(db_url):
    """Function to open the specified SQLite database and return a Connection
    object to it. If the requisite table structure does not exist, it will be
    created.
    """

    # Connect to database, using auto-commit
    conn = sqlite3.connect(database=db_url, isolation_level=None)

    # Look for fingerprints table
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    found = {'files': False, 'dirs': False }
    for table in cursor.fetchall():
        logging.debug("Found table '" + table[0] + "'")
        for fp_table in table_names:
            if (table[0] == table_names[fp_table]):
                logging.debug("Found " + fp_table + " fingerprint table '" + 
                              table[0] + "'.")
                found[fp_table] = True

    # If not found, create
    if not(found['files']):
        cursor.execute("CREATE TABLE '" + table_names['files'] + 
                       "'(File_ID INTEGER PRIMARY KEY AUTOINCREMENT, " +
                       "Name TEXT, Parent_ID INT, " +
                       "LastModified TEXT, Fingerprint TEXT, Size INT)")
        
    if not(found['dirs']):
        cursor.execute("CREATE TABLE '" + table_names['dirs'] + 
                       "'(Path_ID INTEGER PRIMARY KEY AUTOINCREMENT, " +
                       "Name TEXT, Parent_ID INT)")
        
    return conn

########
# Main #
########

# Parse command-line arguments
cmd_args = parse_args()

# Set up logger
setup_logger(cmd_args.quiet,cmd_args.debug,cmd_args.log)
logging.debug('Command-line arguments: %s', vars(cmd_args))

# Open fingerprint database
with open_db(cmd_args.db) as db_conn:

    # Process the specified directory trees.
    for root in cmd_args.root_dir:
        process_root(root, db_conn)

# Fini!
logging.info('Finished.')
